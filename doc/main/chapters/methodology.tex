
\chapter{Scalable structure detection}

On the previous studies and the proposed methodology

\section{Previous studies}

Before entering to the description of the actual tool development, in this 
section it is going to be explained the previous studies that have been done and
have driven to the taken decisions.

\subsection{Application structure by classification}

Taking into account the motivations, exposed in \ref{s:motivations}, and the
previous works studied and discussed in \ref{related_work} the idea to introduce
a new approach arise, even if as always based on previous foundations.  
 
Our intention is, in principle, just use information from MPI calls, mainly for 
three reasons:
\begin{enumerate*}[label=\roman*)]
  \item It does not needs to instrument the source code of the target
    application since exploit the \texttt{LD\_PRELOAD} capabilities of extrae.
    It is a big deal since the source code is not always available to the
    analyst.
  \item trace size is small compared with traces with more information
    like entry/exit from functions
  \item and as have been argued in \ref{s:soa_discussion} monitoring the MPI 
    calls is enough for having a clue about the general structure of the 
    application.
\end{enumerate*}

The proposal presented in this thesis is to explore a new way to detect the
 general structure of an application by applying clustering. 
The essential point is that the problem has been converted in to a classification 
problem so instead of looking for these itemsets that are being
repeated several times during the execution, close enough one each other, let's
face the problem of arrange the MPI calls that belongs to the same loop to the
same cluster. Then analyze the hierarchical arrangement of these clusters to
detect superloops-subloops relations. Once done, the pseudo-code representation 
construction becomes quite easy. The scalability of this method resides on the 
fact that
HPC applications are strongly repetitive over the time, so the number of unique
MPI calls to cluster remains about constant despite the growth of the execution
time, additionally clustering algorithm such that K-means presents an attractive 
linear complexity and DBSCAN a quasi-lineal in general.

The two previous studies that follows in this section are 
\begin{enumerate*}[label=\roman*)]
  \item since we want to group MPI calls into loops, is important to know what
    is actually identifying a loop
  \item and perform a quantitative demonstration of the scalability of the
    method in terms of number of unique MPI calls for different growing inputs.
\end{enumerate*}
Both studies have been done over executions of the MPI NAS Parallel benchmarks 
in its 3.3 version.

\subsection{Loops feature selection}\label{ss:loops_characterzation}

The key point of the presented method is to clustering MPI calls into loops but
what is actually identifying a loop? The answer is about to figure out what loop
feature or features are able to identify then unequivocally or at least with
less level of aliasing\footnote{Understanding as aliasing when two different
loops are considered the same because impossibility to differentiate throw the
selected metrics}. Without a lot of 
effort we can think that its
position on code, understanding as position the line and the file where the loop
lies, is the feature that will give us more information but the reality is that 
we do not have this information on trace. To have it we would need to insert
some monitors on code or maybe use some sort of dynamic binary instrumentation
like
PIN\footnote{https://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool}
and it would drive to huge traces, a thing to be avoided so we just are going to
rely on {\tt LD\_PRELOAD} that only trace MPI calls with additional
information like its parameters, the call-path and some hardware metrics (even
if it is true that there is also no information about loop iterations in trace,
the MPI calls repetition can be considered as a proxy of iterations)
Being aware of that, the next obvious metrics that in principle can characterize 
a loop is the number of iterations it performs but for sure in an application 
there used to be dozens of
loops and is not ridiculous to think that clustering just with this metric will
leads to a lot of aliasing. That would be true if we think in static number of
iterations but lets think about dynamic number of iterations: The dynamic
iterations of a given loop does not depends only on the number of iterations in
its definition but also on the number of iterations on the definition of the
parent loops such that if there are two loops having $n$ and $n$ iterations (so
having aliasing on static number of iterations) being one nested on the other, 
in the dynamic domain, they will have $n$ and $n^2$ iterations, undoing the aliasing.
This is just an starting point, nested loops will be unambiguously identified so
it is okay for most of the applications (the most simple) but there still some
situations where we can have aliasing. The situation where two loops
lies on the same loop nesting level and have the same number of static
iterations will drive to aliasing. This situation is not so probable (at least
on the NPB benchmarks that is the set of benchmarks used for validation) but
since it has been detected in some cases it has to be covered. Further, the next
metric that can identify a given loop is the work that does, i.e. the
iteration time. Two different loops used to execute different work so it is
likely to have a different duration per iteration. An appropriate metric for
quantify this value is to take an aggregate of all iterations duration, i.e.
the mean. So, in this first qualitative approach, the conclusion is we can 
identify with high probability of 
unambiguity the loops with two metrics:
\begin{enumerate*}[label=\roman*)] 
  \item Number of dynamic iterations
  \item Iterations mean time
\end{enumerate*}

Additionally to this qualitative discussion, it is crucial to drive also a 
quantitative analysis. In order to do so, 
several features, the described above and some others, are collected from several 
executions and a feature selection is then done by means of two well-known methods
\footnote{Feature selection is
the process of selection a subset of relevant features for use in the model
construction.}.
The main objective is to confirms or reject our intuition about number of
iterations and iteration mean time, and to find out other possible features that
can help on the task of identify loops.
The first used technique is PCA analysis that permit to get hints 
about how features are related between them and the last is a variable 
importance analysis by means of Random Forest method. On next sections will be 
explained how data have been gathered and the analysis performed over it.  

\subsubsection{Data acquisition}

Previously have been discussed how number of dynamic 
iterations and iterations mean time can help. Additionally to these information
\begin{enumerate*}[label=\roman*)]
    \item IPC 
    \item and some instruction types counters 
\end{enumerate*}
will be also gathered.
About the former, we would need mean number of instructions and mean number of 
cycles per iterations. The reason is that they maybe can contribute because some 
differences in the performance between loops. The intuition says that
hardly can help for this purposes because, among other reasons, it depends a lot
on other factors than the application. Remember in previous sections have been argued
performance information is not optimal for syntactic analysis but we can not
discard it categorically before do a quantitative analysis. The reason for the
latest is that it can be thought if two loops performs different work, the
relative quantity with total number of instructions of scalar, floating point 
or memory operations will differ. In order to do so, a set of hardware
counters have been defined. The decision about what hardware counters
pick have been dramatically restricted because the capabilities of the
hardware used for the experiments. This set consist on:
\begin{enumerate*}[label=\roman*)]
  \item Number of instructions
  \item number of cycles 
  \item number of unconditional branches
  \item number of conditional branches 
  \item total number of branches
  \item number of floating-point instructions
  \item and number of memory loads.
\end{enumerate*}
Finally we also want to collect an unambiguously identification of loops
since we want to be able to accurately relate these metrics to a given loop.
The identification is done by hash function with code line and file.

As has been introduced above, trace does not have explicit information about 
loops so it should be collected from other sources. The reason is that the typical
tracing method is by means of the {\tt LD\_PRELOAD} mechanism, so tracer library just
can get information at shared library calls (like MPI, GOMP, \dots). The alternative
is to manually instrument the user code and fire events with the desired information
by means of the tracer library API, in this case Extrae. Since the process of
manually insert monitors presents to be tough for large codes has been decided
to do it automatically using a source-to-source compiler, in this case
Mercurium. Modifications on Mercurium have been done what have consisted
basically on develop a new compilation phase that injects the desired
monitors on the desired places in the code. Now, at execution time, those
monitors  fires the desired information to trace. 
All developments for this purpose are explained in annex \ref{ann:automatic_loops_charac} 
in more detail.

Slightly different approaches have been applied in every case. In the case of
the PCA, since we wanted to characterize loops as a single entity, events are
fired at the beginning and at the end of every loop marking the loop boundaries
with just loop identification information, furthermore also events are fired at 
the beginning and at the end of loops iterations, in this case with all the
mentioned hardware counters. Since tracefile presents to grow to dozens of
Gigabytes for not so big executions and executions tends to be really stable
just picking several iterations seems to be enough, so have been decided to 
instead of instrument all iterations of all loops, an iteration is instrumented 
given a probability. For these experiments the probability was set to 20\%.
Finally to keep track of how many iterations has been instrumented over the
total, an extra event with total number of executed iterations (instrumented or
not) is also fired to trace for every loop.

For random forest analysis data acquisition is done from another perspective, 
in this case what we wanted is the same information that will be available on
production traces but labeled with the information of to what loop it belongs
to, so these traces can be understood as training  traces. To do so the
functions that marks entry/exit of loops does not fire any event to trace but
keep track of the loops nesting hierarchy. Loop identification (or
identifications when in a nested loops) is only fired to trace before an MPI call. 

After data have been gathered to traces, post-process is done for
prepare it for the performed analysis. On next section will be explained 
how this data have been analyzed by means of the two selected methods. 

\subsubsection{Data analysis}

The first selected technique to drive the
analysis has been the Principal Component Analysis (PCA): Data is linearly 
transformed in such a way it can be expressed in principal components that are 
sorted by the amount of variance that can explain and are orthogonal between 
them. It allows to identify patterns in data and expressing the data in 
such a way to highlight their similarities and differences. Once these patterns 
are found data can be compressed by reducing the number of dimensions with not 
much loss of information.  For improve
understandability of the PCA, Variable factor map is used: It
presents a view of the projection of the observed variables projected into the
plane spanned by the first two principal components. This shows us the
structural relationship between the variables and the components. The projection
of a variable vector onto the component axis allows us to directly read the
correlation between the variable and the component.

What we wanted to see through the PCA analysis is what features can better
identify loops. To do so what is presented as input to the PCA procedure is a
set of observations that are the loops with a set of features for every one of
them. To prepare the data in this terms, a post-process of traces have been
done. This post-process have consisted on aggregate all information from different
iterations for every loop. This aggregation have been basically perform a
geometrical mean of the gathered features minus for the special case of the
number of iterations. In this last case total number of iterations is not the
total number of instrumented iterations because not all of them have been
instrumented but just a subset. Since the probability of an iteration to be
instrumented is well-known (it has been set by us), the reconstructions is also
trivial, being the total number of iterations:
$$
nit = iit*\frac{1}{\alpha^{\beta+1}}
$$
Being $\alpha$ the probability to be instrumented and $\beta$ the nesting level
of the loop.

After acquire and process the data, at image \ref{fig:sp_pcv_hwc2} it can be
seen the contribution to the variance of every principal component for every NPB
execution. In image \ref{fig:sp_pcv_hwc1} the different variable factor maps are
showed up. About the former just comment that the first principal component can
explain the majority of the variance having a value from about 70\% to above
80\% for the EP case (\ref{fig:ep_pcv_hwc2}). Moving on, the last figure is 
showing us how the variables are correlated between them and also how they are 
correlated with the components. A more detailed analysis have to be done here.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/bt_A_4_pvar01.png}
        \caption{BT}
        \label{fig:bt_pcv_hwc2}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/cg_A_4_pvar01.png}
        \caption{CG}
        \label{fig:cg_pcv_hwc2}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/ep_A_4_pvar01.png}
        \caption{EP}
        \label{fig:ep_pcv_hwc2}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/ft_A_4_pvar01.png}
        \caption{FT}
        \label{fig:ft_pcv_hwc2}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/lu_A_4_pvar01.png}
        \caption{LU}
        \label{fig:lu_pcv_hwc2}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/mg_A_4_pvar01.png}
        \caption{MG}
        \label{fig:mg_pcv_hwc2}
    \end{subfigure}

    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/sp_A_4_pvar01.png}
        \caption{SP}
        \label{fig:sp_pcv_hwc2}
    \end{subfigure}
    \caption{Principal Components variability explanation}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/bt_A_4_varmap01.png}
        \caption{BT}
        \label{fig:bt_pcv_hwc1}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/cg_A_4_varmap01.png}
        \caption{CG}
        \label{fig:cg_pcv_hwc1}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/ep_A_4_varmap01.png}
        \caption{EP}
        \label{fig:ep_pcv_hwc1}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/ft_A_4_varmap01.png}
        \caption{FT}
        \label{fig:ft_pcv_hwc1}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/lu_A_4_varmap01.png}
        \caption{LU}
        \label{fig:lu_pcv_hwc1}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/mg_A_4_varmap01.png}
        \caption{MG}
        \label{fig:mg_pcv_hwc1}
    \end{subfigure}

    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{pcas/sp_A_4_varmap01.png}
        \caption{SP}
        \label{fig:sp_pcv_hwc1}
    \end{subfigure}
    \caption{Variable factor map on NPB with both HWC merged}
\end{figure}

First thing to analyze is whether the first qualitative considerations done at
the very beginning of this section were true or not. About total number of
iterations it can be seen that is the variable better correlated to the 
second principal component in \ref{fig:bt_pcv_hwc1}, \ref{fig:cg_pcv_hwc1},
\ref{fig:ft_pcv_hwc1} and \ref{fig:lu_pcv_hwc1}. In case of
\ref{fig:ep_pcv_hwc1} it is important for first and second PC. About mean 
iteration time it can be seen is highly correlated with first component in
\ref{fig:cg_pcv_hwc1}, \ref{fig:ep_pcv_hwc1} and with the second in
\ref{fig:ft_pcv_hwc1} and \ref{fig:mg_pcv_hwc1}. Both seems to be quite
important in general so the first intuition was not bad at all. The bad news are
that both metrics used to maintain a high correlation between them, in general
negative, what is saying as more (dynamic) iteration a loop has, less iteration
time. It have two lectures:
\begin{enumerate*}[label=\roman*)]
  \item It can be understood because the big loops that drives the execution are
    expensive because does a lot of computations and little function loops with
    simple jobs performs a lot of iterations like for example functions that
    looks for a character in a string.
  \item The other lecture is that since we are counting dynamic iterations,
    subloops for sure will have more iterations that the big outer loops and
    also the iteration time for those big loops is inevitably bigger because
    they are containing those subloops.
\end{enumerate*}
Nevertheless there are some situations where this correlation is not like in
\ref{fig:cg_pcv_hwc1} and \ref{fig:ep_pcv_hwc1}  where they are orthogonal. The
conclusion is that these two metrics can explain a quite good amount of
variability and can avoid aliasing in some cases so the first intuition seems to
be good.

Next thing to analyze is whether the IPC can help at the
classification step mostly on cases where number of iterations and iterations
time are highly correlated that happens more obviously on \ref{fig:bt_pcv_hwc1},
\ref{fig:ft_pcv_hwc1}, \ref{fig:lu_pcv_hwc1} and \ref{fig:mg_pcv_hwc1}. In these
cases it is used to present a moderated positive correlation with iteration mean
time so better IPC when longest iterations. With this data the usefulness or not
about IPC metric is fuzzy so more analysis needs to be done.

Lastly for PCA, it needs to check out how the instructions types counters are
behaving. About branch instruction counters (PAPI\_BR\_UCN\_REL,
PAPI\_BR\_UCN\_REL and PAPI\_BR\_UCN\_REL) it can be said that in general they
are strong positive correlated between them, presents a strong
correlation with first component and is used to be orthogonal with iteration
time mean and total number of iterations in cases when they are strongly
correlated. What it means is that it can explain a lot of variability of the 
dataset. Additionally since all three are explaining the same picking just one
should be enough. About the relative number of load instructions 
(PAPI\_LD\_INS\_REL) it presents a quite different behavior depending on the
execution but in most cases it presents a negative correlation with number of
branches like in \ref{fig:bt_pcv_hwc1}, \ref{fig:cg_pcv_hwc1},
\ref{fig:ft_pcv_hwc1} and \ref{fig:mg_pcv_hwc1} what means that in most cases it
can be used as well as branch counter when there is high correlation between
total iterations and iterations mean time. Lastly, about relative floating
point instructions (PAPI\_FP\_INS\_REL) like before its behavior differs
depending on the execution with respect to the rest of metrics but it is true 
that can explain quite a lot of variance.

% TODO PCA Conclusions
Summing up, \ldots


The second used technique have been random forest for classification
% TODO: Explicar Random Forest
% TODO: Explicar para que lo queremos
% TODO: Explicar el post-proceso de los datos
% TODO: Explicar los resultados
% TODO: Conclusiones

In figure 

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{varimp/bt_A_4_varimp.png}
        \caption{BT}
        \label{fig:bt_varimp}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{varimp/cg_A_4_varimp.png}
        \caption{CG}
        \label{fig:cg_varimp}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{varimp/ep_A_4_varimp.png}
        \caption{EP}
        \label{fig:ep_varimp}
    \end{subfigure}
    
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{varimp/ft_A_4_varimp.png}
        \caption{FT}
        \label{fig:ft_varimp}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{varimp/lu_A_4_varimp.png}
        \caption{LU}
        \label{fig:lu_varimp}
    \end{subfigure}
    \quad
    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{varimp/mg_A_4_varimp.png}
        \caption{MG}
        \label{fig:mg_varimp}
    \end{subfigure}

    \begin{subfigure}[b]{0.3\textwidth}
        \includegraphics[width=\textwidth]{varimp/sp_A_4_varimp.png}
        \caption{SP}
        \label{fig:sp_varimp}
    \end{subfigure}
    \caption{Variable importance by Random Forest method on NPB}
\end{figure}

\subsection{Scalability}\label{ss:scalability}

Clustering will not be done with all MPI events presented on the whole trace but
just with these events that results from a compression from the original
tracefile. This compression consists on the aggregation of information from 
different instances of the same MPI event like inter-arrival time, number of
instances, duration, \ldots that since applications used to present very repetitive 
behavior the compression ratios will presumably be high. There is not the
responsibility of this section to describe the algorithm followed to do so that
is going to be described in \ref{ss:trace_reduction} but to demonstrate by a
quantitative analysis that this assumption is true. The experiments were done
by extracting traces from NPB suite with different problem sizes in a weak
scaling fashion and figure out how many unique MPI events are retrieved 
in every case for the clustering phase.  


\section{Proposed methodology}

In our methodology we rely on the observation of the MPI calls to infer the
fundamental internal structure of the application, the reason is that the
principal loops that drives the execution on HPC applications used to contain
the MPI calls needed to perform the communications between the different
processes, so looking at them should be enough for an overview of the structure
in most cases. The proposal consists on a three fundamental pipelined steps:
\begin{enumerate*}[label=\roman*)]
  \item Trace reduction: It consist on the trace parsing, aggregation and
    derivation of the metrics related to the MPI calls.
  \item Loops clustering: This step is where the gathered MPI calls are
    clustered and every one of the resulting clusters are considered as different
    loops.
  \item Loops merge: Once the calls are grouped into loops, the relationships
    between these loops have to be studied such that the actual structure of the
    application in terms of superloop-subloop relations is showed up.
  \item Pseudocode construction: Final step is about building up a
    representation of the detected structure such a way it ease the
    interpretation of data. The chosen format have been pseudo-code with
    attached performance data.
\end{enumerate*}
In figure \ref{fig:methodology_workdlow} it can be seen an overview of the 
explained architecture.

\begin{figure}[]
  \centering
  \includegraphics[width=\textwidth]{diagram/methodology_diagram}
  \caption{Methodology workflow diagram}
  \label{fig:methodology_workdlow}
\end{figure}

\subsection{Trace reduction}\label{ss:trace_reduction}

This phase is a sort of pre-process of data. Data is presented as a tracefile
that is basically a sequence of timestamped events and it is transformed to a
set of MPI calls with attached information that will be the input for the next
phase, i.e. the clustering. This phase performs two actions,
\begin{enumerate*}[label=\roman*)]
  \item Reduction
  \item and aggregation \& derivation
\end{enumerate*}

About the former, the reduction consists on collapse all the same MPI calls that
are sparsed among all the time axis. Very inspired on \cite{noeth2009scalatrace} two MPI calls
results to be equal if and only if have the same signature. In our case the
signature is defined by the entire callstack, i.e. a sequence of pairs 
$(file, line)$ that unambiguously will define the dynamic position in code of a
given MPI call. Additionally contains the rank-id.

We can define $T$ as the sequence of mpi calls ordered by time and $|T|$ the 
total number of mpi calls that is function of the size of the input trace. 
Now, $c \in T$ is an MPI call being $t(c)$ the entry instant on this call and 
$signature(c)$ its signature. Having 
$\Omega$ the set of reduced $c$, then $r:T\rightarrow\Omega$ is the reduction 
function. This is an exhaustive function such that $\forall c \in T \medspace \exists 
\omega \in \Omega : r(c)=\omega$ and fulfills $\forall x,y \in T : 
signature(x)=signature(y) \Leftrightarrow r(x)=r(y)$. Also $\omega$ elements
collect all times from reduced calls such that $\forall c \in T \medspace
\exists \omega \in \Omega : r(c)=\omega \Leftrightarrow t(c) \in T(\omega)$
being $T(\omega)$ an ordered list of times. Additionally elements in $T$ could 
have some features $\lambda \in \Lambda$ attached that becomes to ordered list 
on $\Omega$ space similar to $T(\omega)$. 

Once the reduction is finnished next step is to perform the aggregation and
derivation. Aggregation consists on aggregate the features
belonging to those sparsed calls, generally the aritmetic mean on for example
the size of the messages, duration of the call and so on. Derivation 
consist on extract these needed information that is not
explicit in trace so needs some sort of calculation. On previous sections 
it has been introduced that number of iterations and
iteration mean time among others iteration level information are good fetures 
to classify for loops. On production traces there is no any information about
loops and iterations boundaries so this information should be gathered from a
different source. For sure, this source are the MPI calls, as also has been previously
introduced they act as the fundamental pillars for the general structure
recognition, so they will act as a proxy for these iterations boundaries. What
it means is that we are going to consider number of iterations same think as the
number of repetitions of a given MPI call, and all the iteration-level
information all the information in between two instances of the same MPI call,
for example iteration time will be the time passed between two consecutive
instances of the same call. It can be defined as (and similarly with other
features $\lambda \in \Lambda$): 
$$
\forall \omega \in \Omega : it(\omega)=\frac{\sum\limits_{i=1}^{|T(\omega)|-1} t_{i+1}-t_{i}}{|T(\omega)|-1}
$$

Being $it(\omega)$ the mean iteration time.

The algorithm developed for this first step is quite intuitive. It basically
consists on traverse the tracefile sequentially and every time an MPI call is
detected, all the needed information is gathered. Then whether a previous MPI call
with the same signature exists is checked out, if no it is added to the
$\Omega$ set but if yes it is merged with the already existing. Even if the
fundamental idea is quite simple, implementing it, in a relatively efficient
way, for paraver traces is a little bit tricky because two factors.
\begin{enumerate*}[label=\roman*)]
  \item Communication information for p2p operations like size or partner are different events from
    MPI call events so communications have to be matched with the actual calls
  \item and in order to avoid overflows on hardware counter numbers, extrae 
    reset to 0 the these counters every time it is fire to trace, so for example to
    calculate number of instructions from one instance of an MPI call to its
    nexts is not as direct as calculate the difference.
\end{enumerate*}

Lets define $\Sigma = T \cup \Psi \cup \Delta$ being $\Psi$ the set with
all communications in execution and $\Delta$ all the hardware counters values
fired to trace. In pseudocode \ref{pc:reduction_phase} it can be seen the
developed algorithm that deals with the explained characteristics of the paraver
trace format. In order to deal with communications and hardware counters that
lies on different events that the MPI call events, there are a set of buffers.
In case of communications (buffers $S$ and $D$) they are used in case when communication arrives, the
calls have not arrive yet. In case of hardware counters (buffer $C$) is for keep
track of values even if they are multiple times set to zero by other mpi call
events.

\begin{pseudocode}{Reduction algorithm}{\Sigma}
\label{pc:reduction_phase}
    S \GETS \emptyset \medspace
    \COMMENT{Set of not matched communications on source} \\
    D \GETS \emptyset \medspace
    \COMMENT{Set of not matched communications on destination} \\
    C \GETS \emptyset \medspace
    \COMMENT{Collection of counters identified by mpi signature} \\
    \FORALL e \in \Sigma \DO 
	\BEGIN 
        \IF e \in \Psi \THEN
        \BEGIN
            \IF origin(e) \in \Omega \THEN
                update(origin(e), e)
            \ELSE
                S \GETS S \cup {e}
            \\
            \IF destination(e) \in \Omega \THEN
                update(destination(e), e)
            \ELSE
                D \GETS S \cup {e}
        \END
        \\
        \ELSEIF e \in \Delta \THEN
        \BEGIN
            \FORALL c \in C \DO
                value(c) = value(c) + e\\
        \END
        \\
        \ELSEIF e \in T \THEN
        \BEGIN
            \IF \exists s \in S : origin(s) = e \THEN
            \BEGIN
                update(e,s)\\
                S \GETS S - {s}\\
            \END
            \\
            \IF \exists d \in D : destination(e) = d \THEN
            \BEGIN
                update(e,d)\\
                D \GETS D -{d}\\
            \END
            \\
            \IF \exists c \in C : signature(c) = signature(e)
            \THEN
            \BEGIN
                updatehwc(e, value(c))\\
                value(c) \GETS 0\\
            \END
            \ELSE
            \BEGIN
                updatehwc(e, 0)\\
                C \gets (signature(e), 0)\\
            \END
            \\
            \IF \exists \omega \in \Omega : signature(\omega) = signature(e)
            \THEN
                merge(\omega, e)
            \ELSE
                \Omega \GETS \Omega \cup {e}
        \END
	\END
	\\

    \RETURN \Omega
\end{pseudocode}

This algorithm presents a linear time complexity (all search in sets are
constant since they have been implemented as hashmaps) $\Theta(|Sigma|)$ that is
basically with the size of the tracefile. Only this serial version have been
developed but there is a lot of space for improvement since the characteristics
of this problem allows to face it with parallel codes. Trace could be split into
several files and perform an algorithm similar to the proposed on every one of
the partitions, once done a reduction among the different results should be
done. Some considerations would be taken into account like for example the
position to do the splits or if it would be need all the communications in a
single file instead of spreaded among all of them. Because time restrictions
have been decided to move this sort of considerations to future work.

\subsection{Loops clustering}

\subsection{Loops merge}

\subsection{Pseudo-code construction}
